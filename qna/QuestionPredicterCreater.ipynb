{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600230895301",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('./VSN Categorization Template-Consolidated.xlsx')\n",
    "\n",
    "df = pd.read_excel(xls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "column :  Keyword\n['Child, Immunization, Common Cold' 'child, Immunization record, school'\n 'person, shingles, chikenpox, varicella' 'immunization, Canada'\n 'Payment, hepatitis B' 'Child, Immunize, MMR, Pregnancy '\n 'Measles, mumps and rubella vaccines' 'Influenza vaccines'\n 'Measles, mumps and rubella vaccines, Pregnancy'\n 'Infants & young children' 'Adults' 'Chickenpox vaccines'\n 'School-age children & teens' 'General immunization'\n 'School-age children & teens, Chickenpox vaccines' 'Vaccine ingredients'\n 'Where to get immunized' 'International travel, 2 months, immunization'\n nan 'Shingles vaccines']\ncolumn :  Who is writing this\n['Unknown ' 'Parent' 'Mother' 'Adult' 'Child' 'Elderly' 'Grandparent' nan\n 'Adolescent' 'Sibling' 'parent' 'adult' 'grandparent' 'elderly' 'Unknown'\n 'mother' 'unknown' 'adolescent']\ncolumn :  Subject - Person\n['Child' nan 'Infant/baby' 'Adolescent' 'Girl' 'Baby' 'General Public'\n 'Adult' 'Newborn' 'Grandchild' 'Family' 'Parent' 'Elderly' 'Unknown '\n 'Sibling' 'infant/baby' 'child' 'Grandparent' 'adolescent' 'adult' '-'\n 'elderly' 'unknown ']\ncolumn :  Subject 1 - Immunization\n['Immunization' 'Immunization Record' 'Immunity' 'Immunization Required'\n nan 'Immunization Safety' 'Vaccination' 'Immunization General'\n 'Immunization Schedule' 'Generic' 'immunity' 'vaccination'\n 'immunization schedule' 'i']\ncolumn :  Subject 2 - Vaccination / General\n[nan 'School' 'Vaccination' 'Vaccine Cost' 'Pregnancy' 'Effectiveness'\n 'Antibody' 'Booster' 'Protection' 'Vaccine Ingredients' 'Travel'\n 'Vaccine Education/Info' 'Appointment' 'Safety' 'Prescription'\n 'Vaccine safety' 'Work' 'Health Insurance/care' 'Generic' 'school'\n 'travel' 'safety' 'booster' 'immunity' 'protection' 'pregnancy' 'generic'\n 'vaccine ingredients']\ncolumn :  Disease 1\n['Common cold' nan 'Shingles' 'Mumps' 'Measles' 'Chickenpox'\n 'Pneumococcal (Pneumonia)' 'Diphtheria' 'Pertussis' 'Hepatitis'\n 'Human papillomavirus (HPV)' 'Rabies' 'Meningococcal (Meningitis)'\n 'common cold' 'Influenza (Flu)' 'Flu (Influenza)' 'Tuberculosis (TB)'\n 'Tuberculosis (TB, BCG)' 'Cancer' 'Rubella' 'Malaria' 'Meningitis'\n 'Tetanus' 'Poliomyelitis' 'Varicella (Chickenpox)' 'Rotavirus'\n '(MMR) Measles / Mumps / Rubella' 'Sexually Transmitted Diseases'\n 'Asthma' '-' 'Hepatitis A' 'allergy' 'Overweight and Obesity' 'rabies'\n 'Tick-borne encephalitis' 'Autism' 'rubella' 'Allergy' 'Hepatitis B'\n 'Typhoid' 'Pulmonaary fibrosis' 'Dengue' 'mouth, hand and foot disease'\n 'Diabetes' 'Genital Herpes (Herpes Simplex Virus)']\ncolumn :  Disease 2\n[nan 'Chickenpox' 'Mumps' 'Cancer' 'Hepatitis' 'Tetanus' 'Shingles'\n 'Measles' 'Rabies' 'Diphtheria' 'Poliomyelitis' 'Cholera'\n 'Varicella (Chickenpox)' 'Pneumococcal (Pneumonia)' 'Typhoid'\n 'Influenza (Flu)' 'Meningococcal (Meningitis)' 'Rubella' 'Pertussis'\n '(MMR) Measles / Mumps / Rubella'\n '(DTap) Diphtheria / Tetanus / Pertussis' '-'\n 'Human papillomavirus (HPV)' 'General vaccine safety information'\n 'Tuberculosis (TB, BCG)' 'general vaccine safety information' 'toxoid'\n 'Hepatitis A&B' 'Hepatitis A' 'Tick-borne encephalitis' 'rubella'\n 'Hepatitis B' 'measles' 'pneumococcal (Pneumonia)' 'Rotavirus' 'Dengue']\ncolumn :  Vaccine 1\n[nan 'Varicella (Chickenpox)' 'Hepatitis B'\n '(MMR) Measles / Mumps / Rubella' 'Influenza (Flu)' 'Tetanus'\n 'Hepatitis A&B' '(DTap) Diphtheria / Tetanus / Pertussis' 'Hepatitis A'\n 'Measles' 'Shingles' 'Pertussis'\n '(Dtap+IPV+Hib) Diphtheria/Tetanus/Pertussis/Polio/Hib' 'Rabies'\n '(Dtap+Hep B+IPV) Diphtheria/Tetanus/Pertussis/Hep B/Polio'\n '(DTap) Diphtheria/Tetanus/Pertussis' 'Rotavirus'\n 'Tuberculosis (TB, BCG)' 'Meningococcal (Meningitis)' 'Poliomyelitis'\n '(MMR) Measles/Mumps/Rubella' '(HPV) Human papillomavirus '\n 'Pneumococcal (Pneumonia)' '(Flu) Influenza' 'Mumps'\n '(Dtap IPV) Diphtheria/Tetanus/Pertussis/Polio' 'Rubella' 'Typhoid'\n 'Diphtheria' 'General vaccine safety information' 'Malaria'\n 'Human papillomavirus (HPV)' 'Hepatitis' 'Tuberculosis (TB)' '-'\n 'Tick-borne encephalitis' '(mmR) Measles / Mumps / Rubella' ' ' 'Dengue']\ncolumn :  Vaccine 2\n[nan '(DTap) Diphtheria / Tetanus / Pertussis' 'Varicella (Chickenpox)'\n '(MMR) Measles / Mumps / Rubella'\n '(MMRV) Measles / Mumps / Rubella / Varicella' 'Shingles' 'Hepatitis B'\n 'Rotavirus' '(Hib) Haemophilus influenzae type b '\n '(MMR) Measles/Mumps/Rubella' 'Hepatitis A' 'Meningococcal (Meningitis)'\n 'Pneumococcal (Pneumonia)' 'Tetanus' 'Typhoid' 'Tuberculosis (TB, BCG)'\n 'Hepatitis A&B' '(Dtap+IPV+Hib) Diphtheria/Tetanus/Pertussis/Polio/Hib'\n '(DTap) Diphtheria/Tetanus/Pertussis' '(Flu) Influenza' 'Rabies'\n 'Hepatitis E' 'Japanese encephalitis' 'Poliomyelitis' 'Cholera'\n 'Diphtheria' 'General vaccine safety information' 'Influenza (Flu)'\n 'Measles' 'Pertussis' 'AEFI' 'high dose' 'clinic' 'wheezing']\ncolumn :  Other -condition, symptom etc\n[nan 'breast milk' 'rash' 'Tuberculin skin test' 'cost' 'clinic'\n 'outreach' 'Fever' 'chemotherapy' 'health passport' 'Pneumo-conjugate-13'\n 'pneumococcal conjuga' 'RSV' 'consent' 'translation' 'email'\n 'prservatives' 'Sexual orientation' 'herpes' 'Celiac, Lactose intolerant'\n 'private clinic' 'heart attack' 'immunocompromised' 'diarrhea'\n 'herpes testing' 'brands' 'swelling'\n 'meningococcal quadrivalent Conjugate' 'TB Test' 'online'\n ' INFANRIX HEXA' 'missing' 'mandatory' 'Men/DPT' 'IUD' 'opt out'\n 'lyme disease' 'pre-pregnancy' 'sick' 'baby' 'availability' 'HBIG '\n 'high risk' 'outbreak' 'employees' 'compromised immune system'\n 'numbing cream ' 'vasovagal' ' ITPurpura' 'public transport'\n 'bronchiectosis' 'form' 'work' 'tattoo' 'adjuvants' '4-in-one'\n 'hantavirus' 'EmoniNail Topical Fungus Treatment' 'draw blood'\n 'delayed reaction, hives' 'Malarone'\n ' hard lump/mass under the skin, near the injection site' 'allergy shots'\n 'weekends arm (?)' 'aluminum' 'Shingrix' 'severe adverse reaction'\n 'Twinrix' 'Energix B' 'pregnant' 'syringe disposal' 'Havrix' 'Vaxigrip'\n 'Cystic Fibrosis lung disease' 'Plantars Warts' 'Titer'\n 'cow milk allergy' 'immune suppressed' 'rashes on waist, itchy and pain'\n 'Arbovirus' 'weigh baby' 'Pap test' 'Twinrix vaccine' 'B12 shot'\n 'Coughing and nasally congested'\n 'low white blood cell count, clyndamyacine antiobiotic' 'Bitten by a dog'\n 'suppressed immune system' 'Gardasil, Cervarix, Condyloma acuminatum.'\n 'mercury' 'Quadracel' 'injury ' 'asymptomatic carrier' 'Dukoral'\n 'pap test' 'Hexavalent vaccine' 'surgery' 'unrelated'\n 'Flu Zone High Dose' 'Legionaries disease' 'Aluminum' 'Kawasaki disease'\n 'PHN' 'preservative-free' 'Globulin' 'Diabetic' 'Splenectomy '\n 'Kinder Shot' 'Post-herpetic neuralgia (PHN)/ Shingrix'\n \"Addison's disease, Zostavax\" 'Fluzone' 'Side effect'\n 'red eyes, soreness and weeping eyes' 'Vaccination Procedure, Emla'\n 'Shingrix, bad reaction' 'Bexserro' 'Barriere' 'Weighed and measured'\n 'Systematic Lupus' 'Husband ' 'doses' 'Side effect '\n 'GBS (full paralysis) ' 'surgery ' 'brother-in-law'\n 'Cousin, immunocompromised' 'Shingrix ' 'Whooping cough' 'Fluviral'\n 'Fluezone, Fluad, Fluviral' 'Infanrix HEXA' 'Aleve' 'vaccine brand'\n 'training ' 'Stelara, Crohns' 'Blood fractions' 'Zostavax/ Shingrix'\n 'TASC Shingles Vaccine study, Shingrix' 'Egg Allergy '\n 'INFANRIX/ Uncontrollable Infantile Spasms (West Syndrome)'\n 'Allergic reaction' 'Four vaccines' 'Vegetarian/Vegan'\n 'Kidney transplant patient' 'Amoxicillin Antibiotics '\n 'Breast-feeding, bottle feeding' 'Husband' 'Tattoo' 'Granchild, child'\n 'Symptoms ' 'Wife (partner)' 'Vaccine hesitant' 'Subject- Adult'\n 'Indigenous status ' 'Shingrix Vaccine' 'needle phobia' 'side effects'\n 'seizeure' 'anaphylaxis' 'blood type' 'appointment' 'presciption'\n 'period' 'redness, swelling' 'reaction' 'exemption' 'bite' 'Side effects'\n 'available' 'fertility' 'alcohol' 'allergic reaction' 'age'\n 'vaccine prep' 'fever' 'immunization package' 'hemophiliac'\n 'Flu clinic, public awareness' 'strains' 'booster' 'allergy. AEFI'\n 'flu mist' 'vaccine clinic' 'respiritory infection, suscetability '\n 'prescription' 'dates' 'options' 'supply' 'reason' 'brand, manufacture'\n 'youth' 'needle-phobic, nasal spray' 'approved' 'high dose'\n 'strep throat' 'cephalosporin' 'heavy metals, mercury' 'sexual health'\n 'eggs' 'nasal spray' 'lung condition, high dose' 'appt.' 'international'\n 'hep c' 'fever, high white blood count' 'earlier' 'quadrivalent'\n 'phone number' 'first aid' 'results' 'achy, vomitting' 'anxiety'\n 'permisssion' 'arm hurts' 'short supply' 'fatty liver' 'administer'\n 'intercourse' 'pimple, acne' 'tests']\n"
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    if \"Question\" in x or \"Answer\" in x:\n",
    "        continue\n",
    "    print(\"column : \",x)\n",
    "    print(df[x].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "undesirables = [\"-\", \",\", \"i\", \" \", \"Unknown \",\"unknown \"]\n",
    "for x in df.columns:\n",
    "    if \"Question\" in x or \"Answer\" in x:\n",
    "        continue\n",
    "    df[x] = df[x].replace(undesirables,0)\n",
    "    df[x] = np.where(df[x]==0, 0, 1)\n",
    "\n",
    "df.to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Master Question', 'Master Answer', 'Keyword', 'Who is writing this',\n       'Subject - Person', 'Subject 1 - Immunization',\n       'Subject 2 - Vaccination / General', 'Disease 1', 'Disease 2',\n       'Vaccine 1', 'Vaccine 2', 'Other -condition, symptom etc'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "error\n"
    }
   ],
   "source": [
    "data = []\n",
    "labels = ['Keyword', 'Who is writing this','Subject - Person', 'Subject 1 - Immunization', 'Subject 2 - Vaccination / General', 'Disease 1', 'Disease 2','Vaccine 1', 'Vaccine 2', 'Other -condition, symptom etc']\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        text = row['Master Question'] + row['Master Answer']\n",
    "        xcel_labels = np.zeros(len(labels),dtype=int)\n",
    "        \n",
    "        for idx,x in enumerate(labels):\n",
    "            xcel_labels[idx] = row[x]\n",
    "\n",
    "        data.append([text, list(xcel_labels)])\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/edgarmonis/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/edgarmonis/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "# modules:\n",
    "\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.Random(0).shuffle(data)\n",
    "training_data = data[: 1000]\n",
    "test_data  = data[1000 :]\n",
    "\n",
    "training_samples = [x[0] for x in training_data]\n",
    "training_labels = [x[1] for x in training_data]\n",
    "test_samples = [x[0] for x in test_data]\n",
    "test_labels = [x[1] for x in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing step:\n",
    "def preprocess(sentence):\n",
    "    return sentence\n",
    "\n",
    "porter_stemmer_instance = PorterStemmer()\n",
    "\n",
    "# tokenization step:\n",
    "def tokenize(preprocessed_sentence):\n",
    "    # tokenizing sentence:\n",
    "    token_list = []\n",
    "    tokens = word_tokenize(preprocessed_sentence)\n",
    "    for token in tokens:\n",
    "        # stemming tokens:\n",
    "        token = porter_stemmer_instance.stem(token)\n",
    "        # stop-word and punctuation removal:\n",
    "        if token not in stopwords.words('english') and token not in string.punctuation:\n",
    "            token_list.append(token)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining vectorizer instance for preprocessing, tokenizing, stemming, cleaning input sentences\n",
    "# and for transforming them to tf-idf representations:\n",
    "tf_idf_vectorizer = TfidfVectorizer(lowercase = True, preprocessor = preprocess, tokenizer = tokenize, analyzer = 'word')\n",
    "\n",
    "# training vectorizer while also computing training tf-idf representations:\n",
    "sparse_tf_idf_training_samples = tf_idf_vectorizer.fit_transform(training_samples)\n",
    "\n",
    "# computing validation tf-idf representations:\n",
    "sparse_tf_idf_test_samples = tf_idf_vectorizer.transform(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Keyword\ntrain accuracy :  1.0\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\nWho is writing this\ntrain accuracy :  0.792\n              precision    recall  f1-score   support\n\n           0       0.57      0.09      0.16       129\n           1       0.73      0.97      0.84       331\n\n    accuracy                           0.73       460\n   macro avg       0.65      0.53      0.50       460\nweighted avg       0.69      0.73      0.65       460\n\nSubject - Person\ntrain accuracy :  0.82\n              precision    recall  f1-score   support\n\n           0       0.67      0.34      0.45       158\n           1       0.73      0.91      0.81       302\n\n    accuracy                           0.72       460\n   macro avg       0.70      0.63      0.63       460\nweighted avg       0.71      0.72      0.69       460\n\nSubject 1 - Immunization\ntrain accuracy :  1.0\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       1.00      1.00      1.00       459\n\n    accuracy                           1.00       460\n   macro avg       0.50      0.50      0.50       460\nweighted avg       1.00      1.00      1.00       460\n\nSubject 2 - Vaccination / General\ntrain accuracy :  1.0\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\nDisease 1\ntrain accuracy :  0.818\n              precision    recall  f1-score   support\n\n           0       0.67      0.04      0.07       113\n           1       0.76      0.99      0.86       347\n\n    accuracy                           0.76       460\n   macro avg       0.71      0.51      0.46       460\nweighted avg       0.74      0.76      0.67       460\n\nDisease 2\ntrain accuracy :  0.831\n              precision    recall  f1-score   support\n\n           0       0.78      0.07      0.12       107\n           1       0.78      0.99      0.87       353\n\n    accuracy                           0.78       460\n   macro avg       0.78      0.53      0.50       460\nweighted avg       0.78      0.78      0.70       460\n\nVaccine 1\ntrain accuracy :  0.809\n              precision    recall  f1-score   support\n\n           0       0.83      0.04      0.08       121\n           1       0.74      1.00      0.85       339\n\n    accuracy                           0.75       460\n   macro avg       0.79      0.52      0.47       460\nweighted avg       0.77      0.75      0.65       460\n\nVaccine 2\ntrain accuracy :  1.0\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\nOther -condition, symptom etc\ntrain accuracy :  1.0\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for idx, clss in enumerate(labels):\n",
    "    print(clss)\n",
    "    new_training_labels = [x[idx] for x in training_labels]\n",
    "    new_test_labels = [x[idx] for x in test_labels]\n",
    "    NBClassifier = ComplementNB()\n",
    "    NBClassifier.fit(sparse_tf_idf_training_samples, new_training_labels)\n",
    "\n",
    "    accuracy = NBClassifier.score(sparse_tf_idf_training_samples, new_training_labels)\n",
    "    print(\"train accuracy : \", accuracy)\n",
    "\n",
    "    accuracy = NBClassifier.score(sparse_tf_idf_test_samples, new_test_labels)\n",
    "    predictions = NBClassifier.predict(sparse_tf_idf_test_samples)\n",
    "    print(classification_report(new_test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_k_times_more_negative_than_positive(sample_list, label_list, k):\n",
    "\n",
    "    temp = list(zip(sample_list[:], label_list[:]))\n",
    "    random.Random(0).shuffle(temp)\n",
    "    temp_samples, temp_labels = zip(*temp)\n",
    "\n",
    "    \n",
    "    positive = []\n",
    "    negative = []\n",
    "\n",
    "    for s, l in zip(temp_samples, temp_labels):\n",
    "        if l == 1:\n",
    "            positive.append((s, l))\n",
    "    \n",
    "    for s, l in zip(temp_samples, temp_labels):\n",
    "        if l == 0:\n",
    "            negative.append((s, l)) \n",
    "            if (len(negative) == len(positive) * k):\n",
    "                break\n",
    "    \n",
    "    temp = positive + negative\n",
    "    random.Random(1).shuffle(temp)\n",
    "    temp_samples, temp_labels = zip(*temp)\n",
    "    sparse_temp_samples = tf_idf_vectorizer.transform(temp_samples)\n",
    "    return sparse_temp_samples, temp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Keyword\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\nWho is writing this\n              precision    recall  f1-score   support\n\n           0       0.50      0.01      0.02       129\n           1       0.72      1.00      0.84       331\n\n    accuracy                           0.72       460\n   macro avg       0.61      0.50      0.43       460\nweighted avg       0.66      0.72      0.61       460\n\nSubject - Person\n              precision    recall  f1-score   support\n\n           0       0.52      0.07      0.12       158\n           1       0.67      0.97      0.79       302\n\n    accuracy                           0.66       460\n   macro avg       0.59      0.52      0.46       460\nweighted avg       0.62      0.66      0.56       460\n\nSubject 1 - Immunization\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       1.00      1.00      1.00       459\n\n    accuracy                           1.00       460\n   macro avg       0.50      0.50      0.50       460\nweighted avg       1.00      1.00      1.00       460\n\nSubject 2 - Vaccination / General\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\nDisease 1\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00       113\n           1       0.75      1.00      0.86       347\n\n    accuracy                           0.75       460\n   macro avg       0.38      0.50      0.43       460\nweighted avg       0.57      0.75      0.65       460\n\nDisease 2\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00       107\n           1       0.77      1.00      0.87       353\n\n    accuracy                           0.77       460\n   macro avg       0.38      0.50      0.43       460\nweighted avg       0.59      0.77      0.67       460\n\nVaccine 1\n              precision    recall  f1-score   support\n\n           0       1.00      0.01      0.02       121\n           1       0.74      1.00      0.85       339\n\n    accuracy                           0.74       460\n   macro avg       0.87      0.50      0.43       460\nweighted avg       0.81      0.74      0.63       460\n\nVaccine 2\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\nOther -condition, symptom etc\n              precision    recall  f1-score   support\n\n           1       1.00      1.00      1.00       460\n\n    accuracy                           1.00       460\n   macro avg       1.00      1.00      1.00       460\nweighted avg       1.00      1.00      1.00       460\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for idx, clss in enumerate(labels):\n",
    "    print(clss)\n",
    "    new_training_labels = [x[idx] for x in training_labels]\n",
    "    new_test_labels = [x[idx] for x in test_labels]\n",
    "    NBClassifier = ComplementNB()\n",
    "    new_resampled_training_samples, new_training_labels = give_me_k_times_more_negative_than_positive(training_samples,new_training_labels,1)\n",
    "    NBClassifier.fit(sparse_tf_idf_training_samples, new_training_labels)\n",
    "\n",
    "    accuracy = NBClassifier.score(sparse_tf_idf_test_samples, new_test_labels)\n",
    "    predictions = NBClassifier.predict(sparse_tf_idf_test_samples)\n",
    "    print(classification_report(new_test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "classifier_dict = {}\n",
    "for idx, clss in enumerate(labels):\n",
    "    print(clss)\n",
    "    new_training_labels = [x[idx] for x in training_labels]\n",
    "    new_test_labels = [x[idx] for x in test_labels]\n",
    "    NBClassifier = ComplementNB()\n",
    "    NBClassifier.fit(sparse_tf_idf_training_samples, new_training_labels)\n",
    "\n",
    "    accuracy = NBClassifier.score(sparse_tf_idf_training_samples, new_training_labels)\n",
    "    print(\"train accuracy : \", accuracy)\n",
    "\n",
    "    accuracy = NBClassifier.score(sparse_tf_idf_test_samples, new_test_labels)\n",
    "    predictions = NBClassifier.predict(sparse_tf_idf_test_samples)\n",
    "    print(classification_report(new_test_labels,predictions))\n",
    "    classifier_dict[clss]=NBClassifier"
   ]
  }
 ]
}